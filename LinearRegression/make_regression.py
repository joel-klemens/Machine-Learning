# Generate a random regression problem.
# The input set can either be well conditioned (by default) or have a low rank-fat tail singular profile. 
# See make_low_rank_matrix for more details.
# The output is generated by applying a (potentially biased) random linear regression model 
# with n_informative nonzero regressors to the previously generated input and some gaussian centered noise 
# with some adjustable scale.

import numpy as np

class LinearRegression:
    def __init__(self, learning_rate=0.01, num_iterations=1000):
        # learning rate give the speed where the gradient moves during descent
        self.lr = learning_rate
        self.num_iterations = num_iterations
        self.weights = None
        self.bias = None

    def fit(self, X, y):
        # init parameters
        num_samples, num_features = X.shape
        # for each component set to a 0 
        self.weights = np.zeros(num_features)
        self.bias = 0

        # gradient descent
        # for each value 
        for _ in range(self.num_iterations):
            # for each iteration move down the gradient to approximate w2
            # y = wx + b 
            y_predicted = np.dot(X, self.weights) + self.bias
            # compute gradients
            # numpy.dot(a, b, out=None) dot product of two arrays 
            # remove scaling factor 2 
            dw = (1 / num_samples) * np.dot(X.T, (y_predicted - y))
            db = (1 / num_samples) * np.sum(y_predicted - y)

            # update weights 
            self.weights -= self.lr * dw
            # update bias 
            self.bias -= self.lr * db

    def predict(self, X):
        # approximate values using y = wx + b 
        y_predicted = np.dot(X, self.weights) + self.bias
        return y_predicted